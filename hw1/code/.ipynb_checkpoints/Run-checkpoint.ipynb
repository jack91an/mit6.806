{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import languagemodel as lm\n",
    "\n",
    "np.random.seed(1)  # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_train = lm.readCorpus(\"data/train.txt\")\n",
    "corpus_dev   = lm.readCorpus(\"data/dev.txt\")\n",
    "corpus_test  = lm.readCorpus(\"data/test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " \"n't\",\n",
       " 'quite',\n",
       " 'a',\n",
       " 'notebook',\n",
       " 'i',\n",
       " 'call',\n",
       " 'it',\n",
       " 'a',\n",
       " '<unk>',\n",
       " 'he',\n",
       " 'says',\n",
       " '<END>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a common index (words to integers), mapping rare words (less than 5 occurences) to index 0\n",
    "# nwords = vocabulary size for the models that only see the indexes\n",
    "\n",
    "w2index,nwords = lm.buildIndex(corpus_train+corpus_dev+corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sellers': 0,\n",
       " 'five': 1,\n",
       " 'music': 0,\n",
       " 'redeemed': 0,\n",
       " 'sharply': 2,\n",
       " 'darman': 3,\n",
       " 'food': 4,\n",
       " 'high-grade': 0,\n",
       " 'missing': 0,\n",
       " 'undersecretary': 0,\n",
       " 'attorney': 0,\n",
       " 'midland': 0,\n",
       " 'sir': 0,\n",
       " 'closer': 0,\n",
       " 'blamed': 0,\n",
       " 'easing': 0,\n",
       " 'protection': 0,\n",
       " 'stated': 0,\n",
       " 'electrical': 0,\n",
       " 'dinner': 0,\n",
       " 'improvement': 0,\n",
       " 'pictures': 0,\n",
       " 'portfolio': 5,\n",
       " 'deposits': 6,\n",
       " 'agencies': 7,\n",
       " 'quotations': 0,\n",
       " 'hundreds': 0,\n",
       " 'leaving': 0,\n",
       " 'contentious': 0,\n",
       " 'meaning': 0,\n",
       " 'impossible': 0,\n",
       " 'candidates': 0,\n",
       " 'sec': 8,\n",
       " 'has': 9,\n",
       " 'tonight': 0,\n",
       " 'corn': 0,\n",
       " 'amoco': 0,\n",
       " 'atlantic': 0,\n",
       " 'lawyers': 11,\n",
       " 'assure': 0,\n",
       " 'ferranti': 12,\n",
       " 'certainly': 0,\n",
       " 'his': 13,\n",
       " 'opportunity': 14,\n",
       " 'rapidly': 0,\n",
       " 'become': 15,\n",
       " 'investors': 16,\n",
       " 'announcement': 0,\n",
       " 'threatening': 0,\n",
       " 'reopened': 0,\n",
       " 'concedes': 0,\n",
       " 'vanguard': 0,\n",
       " 'ownership': 19,\n",
       " 'areas': 20,\n",
       " 'manages': 0,\n",
       " 'tough': 115,\n",
       " 'detergent': 22,\n",
       " 'notice': 23,\n",
       " 'request': 0,\n",
       " 'imports': 0,\n",
       " 'channels': 0,\n",
       " 'mph': 0,\n",
       " 'affects': 0,\n",
       " 'outside': 24,\n",
       " 'superfund': 0,\n",
       " 'consultants': 0,\n",
       " 'lawsuit': 886,\n",
       " 'unchanged': 0,\n",
       " 'navy': 0,\n",
       " 'lagging': 0,\n",
       " 'businessman': 0,\n",
       " 'monthly': 0,\n",
       " 'stance': 0,\n",
       " 'enacted': 0,\n",
       " 'dealer': 0,\n",
       " 'death': 0,\n",
       " 'using': 0,\n",
       " 'crown': 0,\n",
       " 'attached': 0,\n",
       " 'while': 26,\n",
       " 'adobe': 27,\n",
       " 'steam': 0,\n",
       " 'omnibus': 0,\n",
       " 'equipped': 0,\n",
       " 'obstacle': 0,\n",
       " 'katz': 0,\n",
       " 'limits': 0,\n",
       " 'kept': 28,\n",
       " 'fast-food': 0,\n",
       " 'services': 29,\n",
       " 'indianapolis': 0,\n",
       " 'listed': 0,\n",
       " 'phillips': 0,\n",
       " 'trouble': 30,\n",
       " 'inaccurate': 0,\n",
       " 'treatment': 0,\n",
       " 'mergers': 0,\n",
       " 'weather': 0,\n",
       " 'initiatives': 0,\n",
       " 'cooperation': 0,\n",
       " 'signature': 0,\n",
       " 'telling': 0,\n",
       " 'affecting': 0,\n",
       " 'defeated': 0,\n",
       " 'upgrade': 0,\n",
       " 'editor': 0,\n",
       " 'recommended': 0,\n",
       " 'rated': 0,\n",
       " 'literary': 0,\n",
       " 'reiterated': 0,\n",
       " 'gave': 0,\n",
       " 'encourage': 0,\n",
       " 'slowdown': 0,\n",
       " 'diamond': 0,\n",
       " 'practice': 0,\n",
       " 'sustained': 0,\n",
       " 'revenues': 0,\n",
       " 'minority': 0,\n",
       " 'loan-loss': 0,\n",
       " 'prize': 0,\n",
       " 'type': 32,\n",
       " 'layoffs': 0,\n",
       " 'times': 717,\n",
       " 'wins': 0,\n",
       " 'case': 34,\n",
       " 'circulation': 35,\n",
       " 'invested': 0,\n",
       " 'long-distance': 0,\n",
       " 'argentina': 0,\n",
       " 'holdings': 38,\n",
       " 'respondents': 0,\n",
       " 'tasks': 0,\n",
       " 'amazing': 0,\n",
       " 'processing': 0,\n",
       " 'these': 39,\n",
       " 'based': 40,\n",
       " 'profitable': 0,\n",
       " 'ohio': 41,\n",
       " 'once': 42,\n",
       " 'integration': 0,\n",
       " 'desire': 0,\n",
       " 'voluntary': 43,\n",
       " 'discipline': 0,\n",
       " 'variety': 44,\n",
       " 'fbi': 0,\n",
       " 'throughout': 45,\n",
       " 'buyer': 0,\n",
       " 'peak': 0,\n",
       " 'coming': 46,\n",
       " 'greece': 0,\n",
       " 'hurdle': 0,\n",
       " 'addition': 47,\n",
       " 'widow': 0,\n",
       " 'kansas': 0,\n",
       " 'attempted': 0,\n",
       " 'products': 48,\n",
       " \"'d\": 49,\n",
       " 'roebuck': 0,\n",
       " 'sen.': 50,\n",
       " 'volatility': 0,\n",
       " 's&l': 0,\n",
       " 'etc.': 0,\n",
       " 'think': 51,\n",
       " 'furthermore': 0,\n",
       " 'spreading': 0,\n",
       " 'slack': 0,\n",
       " 'i.': 0,\n",
       " 'reinforce': 0,\n",
       " 'businesses': 0,\n",
       " 'halts': 0,\n",
       " 'midnight': 0,\n",
       " 'mrs.': 52,\n",
       " 'spot': 0,\n",
       " 'ec': 0,\n",
       " 'laid': 0,\n",
       " 'approximately': 0,\n",
       " 'texaco': 0,\n",
       " 'p.m.': 53,\n",
       " 'toronto': 0,\n",
       " 'striking': 0,\n",
       " 'pursue': 0,\n",
       " 'powerful': 54,\n",
       " 'sought': 0,\n",
       " 'technology': 55,\n",
       " 'without': 56,\n",
       " 'germans': 0,\n",
       " 'dated': 0,\n",
       " 'accepted': 0,\n",
       " 'dreyfus': 0,\n",
       " 'trading': 57,\n",
       " 'both': 58,\n",
       " 'pricings': 0,\n",
       " 'considered': 59,\n",
       " 'proceed': 0,\n",
       " 'releases': 0,\n",
       " 'breakers': 60,\n",
       " 'merely': 0,\n",
       " 'herself': 0,\n",
       " 'yields': 0,\n",
       " 'recent': 61,\n",
       " 'democratic': 0,\n",
       " 'frightened': 0,\n",
       " 'incentives': 0,\n",
       " 'plant': 62,\n",
       " 'showed': 0,\n",
       " 'investigator': 0,\n",
       " 'fundamental': 63,\n",
       " 'refineries': 0,\n",
       " 'happen': 65,\n",
       " 'undercut': 0,\n",
       " 'guy': 0,\n",
       " 'according': 66,\n",
       " 'offers': 67,\n",
       " 'particularly': 723,\n",
       " 'merchant': 0,\n",
       " 'stanley': 0,\n",
       " 'decades': 0,\n",
       " 'past': 68,\n",
       " 'tools': 0,\n",
       " 'initially': 0,\n",
       " 'flights': 0,\n",
       " 'plunged': 70,\n",
       " 'awarded': 0,\n",
       " 'revived': 0,\n",
       " 'create': 0,\n",
       " 'high-school': 0,\n",
       " 'conditions': 0,\n",
       " 'appeals': 0,\n",
       " 'reluctance': 0,\n",
       " 'estimates': 71,\n",
       " 'data': 72,\n",
       " 'barrier': 0,\n",
       " 'notebook': 0,\n",
       " 'globe': 0,\n",
       " 'paying': 0,\n",
       " 'used': 73,\n",
       " 'savings-and-loan': 0,\n",
       " 'divided': 0,\n",
       " 'neither': 0,\n",
       " 'against': 75,\n",
       " 'analyze': 0,\n",
       " 'loans': 76,\n",
       " 'haven': 0,\n",
       " 'supervision': 725,\n",
       " 'appreciate': 0,\n",
       " 'advances': 0,\n",
       " 'd.c.': 0,\n",
       " 'script': 0,\n",
       " 'numerous': 0,\n",
       " 'vice': 77,\n",
       " 'nights': 0,\n",
       " 'mad': 0,\n",
       " 'brand': 0,\n",
       " 'minneapolis': 0,\n",
       " 'philosophy': 0,\n",
       " 'concerning': 0,\n",
       " 'massachusetts': 0,\n",
       " 'approached': 0,\n",
       " 'loaded': 0,\n",
       " 'skeptical': 0,\n",
       " 'administrative': 0,\n",
       " 'airing': 0,\n",
       " 'abandon': 0,\n",
       " 'listening': 0,\n",
       " 'motion': 0,\n",
       " 'preserve': 0,\n",
       " 'intensity': 0,\n",
       " 'hedge': 0,\n",
       " 'purchase': 78,\n",
       " 'offer': 79,\n",
       " 'secure': 0,\n",
       " 'back': 726,\n",
       " 'crew': 0,\n",
       " 'nations': 0,\n",
       " 'downright': 0,\n",
       " 'us$': 0,\n",
       " 'jurisdiction': 0,\n",
       " 'unconstitutional': 0,\n",
       " 'receives': 0,\n",
       " 'members': 80,\n",
       " 'basic': 0,\n",
       " 'available': 81,\n",
       " 'domestically': 0,\n",
       " 'daily': 82,\n",
       " 'continues': 83,\n",
       " 'retirement': 0,\n",
       " 'protect': 84,\n",
       " 'house-passed': 0,\n",
       " 'makers': 85,\n",
       " 'comparison': 0,\n",
       " 'nothing': 86,\n",
       " 'lives': 0,\n",
       " 'billing': 0,\n",
       " 'taylor': 0,\n",
       " 'greenberg': 0,\n",
       " 'track': 0,\n",
       " 'capitol': 0,\n",
       " 'merc': 87,\n",
       " 'proposition': 0,\n",
       " 'agenda': 0,\n",
       " 'goal': 0,\n",
       " 'missed': 0,\n",
       " 'withdrawals': 0,\n",
       " 'distinctive': 0,\n",
       " 'medical': 0,\n",
       " 'index': 89,\n",
       " 'numbers': 0,\n",
       " 'extend': 0,\n",
       " 'observers': 0,\n",
       " 'wooing': 0,\n",
       " 'unspecified': 0,\n",
       " 'interests': 90,\n",
       " 'banking': 91,\n",
       " 'commitments': 0,\n",
       " 'fabric': 0,\n",
       " 'standpoint': 0,\n",
       " 'insufficient': 0,\n",
       " 'surprise': 0,\n",
       " 'managers': 92,\n",
       " 'everywhere': 0,\n",
       " 'christian': 0,\n",
       " 'example': 93,\n",
       " 'breaker': 0,\n",
       " 'quoted': 0,\n",
       " 'trans': 0,\n",
       " 'dismiss': 0,\n",
       " 'guilty': 0,\n",
       " 'strengthen': 0,\n",
       " 'indicated': 0,\n",
       " 'morris': 94,\n",
       " 'motor': 0,\n",
       " 'photographic': 0,\n",
       " 'pretax': 0,\n",
       " 'commentary': 0,\n",
       " 'reference': 0,\n",
       " 'merit': 0,\n",
       " 'affair': 0,\n",
       " 'kaiser': 0,\n",
       " 'idaho': 0,\n",
       " 'bank-backed': 0,\n",
       " 'vacant': 0,\n",
       " 'falls': 0,\n",
       " 'comparisons': 0,\n",
       " 'maneuver': 0,\n",
       " 'mainframes': 0,\n",
       " 'behalf': 0,\n",
       " 'discount': 96,\n",
       " 'recover': 0,\n",
       " 'for': 97,\n",
       " 'racked': 0,\n",
       " 'contracts': 98,\n",
       " 'recording': 0,\n",
       " 'owns': 0,\n",
       " 'sentenced': 0,\n",
       " 'drama': 0,\n",
       " 'upset': 0,\n",
       " 'congressional': 18,\n",
       " 'generating': 0,\n",
       " 'compact': 0,\n",
       " 'wear': 0,\n",
       " 'nasa': 0,\n",
       " 'starts': 0,\n",
       " 'questions': 99,\n",
       " 'st.': 0,\n",
       " 'martin': 0,\n",
       " 'himself': 0,\n",
       " 'leverage': 0,\n",
       " 'drop': 100,\n",
       " '<unk>': 101,\n",
       " 'professionals': 0,\n",
       " 'morning': 102,\n",
       " 'n.j.': 103,\n",
       " 'performers': 0,\n",
       " 'equal': 0,\n",
       " 'dubbed': 0,\n",
       " 'laptop': 0,\n",
       " 'entirely': 0,\n",
       " 'anybody': 0,\n",
       " 'about': 904,\n",
       " 'plc': 104,\n",
       " 'cultural': 0,\n",
       " 'starting': 0,\n",
       " 'respected': 0,\n",
       " 'positions': 591,\n",
       " 'likes': 0,\n",
       " 'turn': 105,\n",
       " 'altman': 0,\n",
       " 'owned': 0,\n",
       " 'segments': 0,\n",
       " 'subsidiary': 106,\n",
       " 'always': 107,\n",
       " 'probably': 108,\n",
       " 'costa': 0,\n",
       " 'stocks': 109,\n",
       " 'offered': 110,\n",
       " 'concept': 0,\n",
       " 'gap': 0,\n",
       " 'lines': 111,\n",
       " 'recorder': 0,\n",
       " 'population': 113,\n",
       " 'post': 114,\n",
       " 'interviewed': 0,\n",
       " 'lawson': 0,\n",
       " 'e': 0,\n",
       " 'flexibility': 0,\n",
       " 'preferred': 21,\n",
       " 'board': 116,\n",
       " 'standing': 0,\n",
       " 'comments': 0,\n",
       " 'sky': 0,\n",
       " 'unexpected': 0,\n",
       " 'wishes': 0,\n",
       " 'attractive': 0,\n",
       " 'conventional': 0,\n",
       " 'foods': 0,\n",
       " 'interfere': 0,\n",
       " 'fire': 0,\n",
       " 'cie': 0,\n",
       " 'mines': 0,\n",
       " 'miners': 0,\n",
       " 'computerized': 0,\n",
       " 'burdens': 0,\n",
       " 'high': 117,\n",
       " 'valued': 0,\n",
       " 'resulted': 0,\n",
       " 'turned': 731,\n",
       " 'peter': 119,\n",
       " 'functions': 0,\n",
       " 'rupert': 0,\n",
       " 'useful': 0,\n",
       " 'tune': 0,\n",
       " 'threatened': 0,\n",
       " 'alcohol': 0,\n",
       " 'supplying': 0,\n",
       " 'extra': 0,\n",
       " 'communist': 0,\n",
       " 'major': 120,\n",
       " 'lived': 0,\n",
       " 'indicates': 0,\n",
       " 'former': 121,\n",
       " 'unfair': 0,\n",
       " 'disappointed': 0,\n",
       " 'political': 122,\n",
       " 'hefty': 0,\n",
       " 'program-trading': 0,\n",
       " 'months': 123,\n",
       " 'full': 124,\n",
       " 'altogether': 0,\n",
       " 'thousand': 0,\n",
       " 'student': 0,\n",
       " 'subscribers': 0,\n",
       " 'ways': 125,\n",
       " 'stephen': 0,\n",
       " 'lambert': 0,\n",
       " 'commute': 0,\n",
       " 'inc.': 126,\n",
       " 'felt': 0,\n",
       " 'commenting': 0,\n",
       " 'goods': 127,\n",
       " 'toward': 128,\n",
       " 'days': 233,\n",
       " 'content': 0,\n",
       " 'except': 0,\n",
       " 'restricted': 0,\n",
       " 'alternatives': 0,\n",
       " 'affiliated': 0,\n",
       " 'confident': 0,\n",
       " 'flat': 129,\n",
       " 'cup': 0,\n",
       " 'lined': 0,\n",
       " 'near-term': 0,\n",
       " 'consume': 0,\n",
       " 'bringing': 0,\n",
       " 'francisco': 0,\n",
       " 'supplier': 0,\n",
       " 'spokesman': 391,\n",
       " 'responses': 0,\n",
       " 'defendants': 0,\n",
       " 'expenditures': 0,\n",
       " 'moderate': 0,\n",
       " 'volume': 130,\n",
       " 'manufacturing': 131,\n",
       " 'jr': 0,\n",
       " 'ibm': 132,\n",
       " 'criticized': 0,\n",
       " 'mehl': 0,\n",
       " 'journalism': 0,\n",
       " 'decade': 0,\n",
       " 'posner': 133,\n",
       " 'u.s.a': 0,\n",
       " 'beef': 0,\n",
       " 'lows': 0,\n",
       " 'ends': 0,\n",
       " 'lackluster': 0,\n",
       " 'fancy': 0,\n",
       " 'funded': 0,\n",
       " 'encouraged': 135,\n",
       " 'disappear': 0,\n",
       " 'pull': 0,\n",
       " 'believes': 0,\n",
       " 'distributed': 0,\n",
       " 'hand': 137,\n",
       " 'o.': 0,\n",
       " 'manufacture': 0,\n",
       " 'helped': 139,\n",
       " 'consulting': 0,\n",
       " 'film': 0,\n",
       " 'will': 793,\n",
       " 'engineer': 0,\n",
       " 'impression': 0,\n",
       " 'cushion': 0,\n",
       " 'joint': 798,\n",
       " 'customer': 0,\n",
       " 'usair': 0,\n",
       " 'until': 140,\n",
       " 'random': 0,\n",
       " 'expect': 585,\n",
       " 'see': 734,\n",
       " 'exceeded': 0,\n",
       " \"'\": 142,\n",
       " 'nearly': 143,\n",
       " 'cities\\\\/abc': 0,\n",
       " 'tons': 822,\n",
       " 'statistical': 0,\n",
       " 'shield': 0,\n",
       " 'time': 144,\n",
       " 'white': 145,\n",
       " 'engines': 0,\n",
       " 'lagged': 0,\n",
       " 'fifth': 146,\n",
       " 'stakes': 0,\n",
       " 'controlled': 0,\n",
       " 'reformers': 0,\n",
       " 'television': 147,\n",
       " 'created': 74,\n",
       " 'spate': 0,\n",
       " 'denied': 148,\n",
       " 'celebrity': 0,\n",
       " 'fully': 0,\n",
       " 'dive': 0,\n",
       " 'single-a-<NUM>': 0,\n",
       " 'holding': 149,\n",
       " 'plot': 0,\n",
       " 'hang': 0,\n",
       " 'pros': 0,\n",
       " 'acquire': 150,\n",
       " 'opposed': 0,\n",
       " 'serve': 151,\n",
       " 'pressures': 0,\n",
       " 'takeovers': 152,\n",
       " 'receiving': 0,\n",
       " 'moves': 153,\n",
       " 'partnership': 0,\n",
       " 'guys': 0,\n",
       " 'own': 154,\n",
       " 'comparable': 0,\n",
       " 'need': 155,\n",
       " 'pennsylvania': 0,\n",
       " 'pro': 0,\n",
       " 'paribas': 0,\n",
       " 'cause': 156,\n",
       " 'noriega': 0,\n",
       " 'lost': 157,\n",
       " 'intense': 0,\n",
       " 'pulling': 0,\n",
       " 'everything': 158,\n",
       " 'plummeted': 159,\n",
       " 'and': 160,\n",
       " 'watches': 0,\n",
       " 'ad': 161,\n",
       " 'bozell': 0,\n",
       " 'signed': 0,\n",
       " 'accepting': 0,\n",
       " 'broaden': 0,\n",
       " 'wanted': 0,\n",
       " 'clean': 0,\n",
       " 'interesting': 0,\n",
       " 'slow': 0,\n",
       " 'providing': 0,\n",
       " 'trades': 972,\n",
       " 'appetite': 0,\n",
       " 'aerospace': 163,\n",
       " 'forces': 0,\n",
       " 'targets': 0,\n",
       " 'triggered': 0,\n",
       " 'opened': 164,\n",
       " 'strength': 165,\n",
       " 'uncommon': 0,\n",
       " 'switched': 0,\n",
       " 'recommend': 0,\n",
       " 'seat': 0,\n",
       " 'consent': 0,\n",
       " 'spouses': 0,\n",
       " 'explains': 0,\n",
       " 'miles': 0,\n",
       " 'northeast': 0,\n",
       " 'strikes': 0,\n",
       " 'then': 166,\n",
       " 'carl': 0,\n",
       " 'finishing': 0,\n",
       " 'accomplish': 0,\n",
       " 'heavy': 167,\n",
       " 'draft': 0,\n",
       " 'spoke': 0,\n",
       " 'maintain': 0,\n",
       " 'usual': 0,\n",
       " 'b-<NUM>': 0,\n",
       " 'earlier': 168,\n",
       " 'requires': 0,\n",
       " 'spirit': 0,\n",
       " 'house-senate': 0,\n",
       " 'largest': 169,\n",
       " 'appears': 170,\n",
       " 'cincinnati': 0,\n",
       " 'ranking': 0,\n",
       " 'ftc': 0,\n",
       " 'talent': 0,\n",
       " 'monitoring': 0,\n",
       " 'totaling': 0,\n",
       " 'proceeding': 0,\n",
       " 'corp.': 171,\n",
       " 'financing': 172,\n",
       " 'claimed': 0,\n",
       " 'produced': 173,\n",
       " 'visible': 0,\n",
       " 'yellow': 0,\n",
       " 'my': 174,\n",
       " 'establishing': 0,\n",
       " 'resulting': 0,\n",
       " 'hertz': 0,\n",
       " 'august': 175,\n",
       " 'there': 1220,\n",
       " 'quick': 177,\n",
       " 'blockbuster': 0,\n",
       " 'abandoned': 0,\n",
       " 'broken': 0,\n",
       " 'kangyo': 0,\n",
       " 'translated': 0,\n",
       " 'microprocessor': 0,\n",
       " 'weakness': 0,\n",
       " 'affairs': 0,\n",
       " 'jose': 0,\n",
       " 'all': 178,\n",
       " 'considerable': 0,\n",
       " 'convicted': 0,\n",
       " 'amsterdam': 0,\n",
       " 'crash': 179,\n",
       " 'highs': 0,\n",
       " 'doing': 180,\n",
       " 'england': 0,\n",
       " 'maturing': 0,\n",
       " 'enthusiastic': 0,\n",
       " 'same': 1000,\n",
       " 'confidence': 181,\n",
       " 'radar': 0,\n",
       " 'respectively': 0,\n",
       " 'cycles': 0,\n",
       " 'clothes': 0,\n",
       " 'houston': 183,\n",
       " 'soviet': 184,\n",
       " 'fill': 0,\n",
       " 'sure': 185,\n",
       " 'continue': 186,\n",
       " 'finger': 0,\n",
       " 'zero-coupon': 0,\n",
       " 'france': 188,\n",
       " 'leases': 0,\n",
       " 'saving': 0,\n",
       " 'dividend': 680,\n",
       " 'entered': 0,\n",
       " 'passive': 0,\n",
       " 'competing': 0,\n",
       " 'wilbur': 0,\n",
       " 'bidder': 0,\n",
       " 'finished': 0,\n",
       " 'declare': 0,\n",
       " 'breaks': 0,\n",
       " 'giuliani': 0,\n",
       " 'turnaround': 0,\n",
       " 'lose': 0,\n",
       " 'place': 189,\n",
       " 'laurence': 0,\n",
       " 'mention': 0,\n",
       " 'known': 190,\n",
       " 'cost': 191,\n",
       " 'stanford': 0,\n",
       " 'balance': 0,\n",
       " 'strategy': 192,\n",
       " 'resumed': 0,\n",
       " 'helmsley': 0,\n",
       " 'rises': 0,\n",
       " 'activities': 0,\n",
       " 'comfortable': 0,\n",
       " 'determined': 0,\n",
       " 'novel': 0,\n",
       " 'moreover': 0,\n",
       " 'though': 193,\n",
       " 'limit': 194,\n",
       " 'exceed': 0,\n",
       " 'companion': 0,\n",
       " 'coins': 0,\n",
       " 'strengths': 0,\n",
       " 'robinson': 0,\n",
       " 'promised': 0,\n",
       " 'bear': 195,\n",
       " 'missile': 196,\n",
       " 'refusal': 0,\n",
       " 'allowance': 0,\n",
       " 'america': 197,\n",
       " 'radical': 0,\n",
       " 'effect': 198,\n",
       " 'hall': 0,\n",
       " 'sector': 0,\n",
       " 'jim': 0,\n",
       " 'harold': 0,\n",
       " '<NUM>-month': 0,\n",
       " 'so-called': 0,\n",
       " 'inherited': 0,\n",
       " 'claim': 0,\n",
       " 'soup': 199,\n",
       " 'supporters': 0,\n",
       " 'clearing': 0,\n",
       " 'whatever': 0,\n",
       " 'david': 200,\n",
       " 'offsetting': 0,\n",
       " 'hill': 1340,\n",
       " 'handling': 0,\n",
       " 'doctors': 0,\n",
       " 'respect': 0,\n",
       " 'social': 201,\n",
       " 'witter': 0,\n",
       " 'unnecessary': 0,\n",
       " 'soon': 202,\n",
       " 'island': 0,\n",
       " 'be': 203,\n",
       " 'lasts': 0,\n",
       " 'active': 0,\n",
       " 'making': 204,\n",
       " 'whose': 205,\n",
       " 'implications': 0,\n",
       " 'warning': 0,\n",
       " 'usa': 0,\n",
       " 'renew': 0,\n",
       " 'lexington': 0,\n",
       " 'improve': 0,\n",
       " 'determine': 0,\n",
       " 'monetary': 0,\n",
       " 'established': 206,\n",
       " 'harris': 0,\n",
       " 'liberals': 0,\n",
       " 'termed': 0,\n",
       " 'different': 207,\n",
       " 'resist': 0,\n",
       " 'job': 208,\n",
       " 'interviews': 0,\n",
       " 'image': 0,\n",
       " 'christopher': 0,\n",
       " 'woman': 0,\n",
       " 'faster': 0,\n",
       " 'delaware': 0,\n",
       " 'kremlin': 0,\n",
       " 'controls': 0,\n",
       " 'struggling': 0,\n",
       " 'differences': 209,\n",
       " 'illustrated': 0,\n",
       " 'baby': 0,\n",
       " 'benchmark': 0,\n",
       " 'wo': 210,\n",
       " 'cautioned': 0,\n",
       " 'pushed': 0,\n",
       " 'publicity': 0,\n",
       " 'planning': 211,\n",
       " 'larry': 0,\n",
       " 'party': 212,\n",
       " 'publications': 0,\n",
       " 'lasted': 0,\n",
       " 'deals': 0,\n",
       " 'stories': 0,\n",
       " 'doubled': 0,\n",
       " 'string': 0,\n",
       " 'waves': 0,\n",
       " 'tests': 0,\n",
       " 'indicating': 0,\n",
       " 'sample': 0,\n",
       " 'rates': 213,\n",
       " 'fannie': 0,\n",
       " 'generate': 0,\n",
       " 'stock-index': 0,\n",
       " 'capability': 0,\n",
       " 'frequent': 0,\n",
       " 'colony': 0,\n",
       " 'itt': 0,\n",
       " 'phones': 0,\n",
       " 'transform': 0,\n",
       " 'youth': 214,\n",
       " 'percent': 0,\n",
       " 'aimed': 0,\n",
       " 'bunch': 0,\n",
       " 'eroded': 0,\n",
       " '&': 216,\n",
       " 'congress': 217,\n",
       " 'depends': 0,\n",
       " 'printing': 0,\n",
       " 'withdrawal': 0,\n",
       " 'served': 0,\n",
       " 'associates': 218,\n",
       " 'organization': 0,\n",
       " 'politics': 0,\n",
       " 'mafia': 0,\n",
       " 'deal': 219,\n",
       " 's.a.': 0,\n",
       " 'sometime': 0,\n",
       " 'warsaw': 0,\n",
       " 'associate': 0,\n",
       " 'venezuela': 0,\n",
       " 'open': 220,\n",
       " 'lyonnais': 0,\n",
       " 'costly': 0,\n",
       " 'nelson': 0,\n",
       " 'majority': 36,\n",
       " 'pence': 0,\n",
       " 'which': 222,\n",
       " 'litigation': 0,\n",
       " 'democrats': 0,\n",
       " 'galileo': 0,\n",
       " 'estate': 223,\n",
       " 'record': 224,\n",
       " 'director': 225,\n",
       " 'really': 226,\n",
       " 'lowered': 0,\n",
       " 'would': 37,\n",
       " 'unwanted': 0,\n",
       " 'goldman': 227,\n",
       " 'continental': 0,\n",
       " 'development': 228,\n",
       " 'show': 229,\n",
       " 'early': 230,\n",
       " 'want': 280,\n",
       " 'economic': 232,\n",
       " 'protest': 0,\n",
       " 'event': 0,\n",
       " 'holiday': 0,\n",
       " 'rental': 0,\n",
       " 'oil': 234,\n",
       " 'decreased': 0,\n",
       " 'computer-guided': 0,\n",
       " 'necessary': 0,\n",
       " 'republicans': 0,\n",
       " 'financiere': 0,\n",
       " 'pa.': 0,\n",
       " 'turner': 0,\n",
       " 'epa': 0,\n",
       " 'j.': 235,\n",
       " 'settle': 0,\n",
       " 'keep': 1181,\n",
       " 'manner': 0,\n",
       " 'enthusiasm': 0,\n",
       " 'whom': 0,\n",
       " 'drain': 0,\n",
       " 'leasing': 0,\n",
       " 'session': 0,\n",
       " 'suppliers': 0,\n",
       " 'unfriendly': 0,\n",
       " 'negotiable': 0,\n",
       " 'familiar': 0,\n",
       " 'tokyo': 0,\n",
       " 'gamble': 0,\n",
       " 'lifting': 0,\n",
       " 'sudden': 0,\n",
       " 'recovery': 0,\n",
       " 'inc': 237,\n",
       " 'says': 136,\n",
       " 'third-quarter': 238,\n",
       " 'incorporated': 0,\n",
       " 'switching': 0,\n",
       " 'circuits': 0,\n",
       " '<NUM>-year': 0,\n",
       " 'apparent': 0,\n",
       " 'crowd': 0,\n",
       " 'belgian': 0,\n",
       " 'lending': 0,\n",
       " 'located': 0,\n",
       " 'help': 618,\n",
       " 'double-digit': 0,\n",
       " 'unsuccessfully': 0,\n",
       " 'yet': 240,\n",
       " 'dissident': 0,\n",
       " 'delta': 0,\n",
       " 'a.c.': 0,\n",
       " 'opens': 0,\n",
       " 'expressed': 0,\n",
       " 'deficit': 749,\n",
       " 'syndicate': 0,\n",
       " 'gains': 241,\n",
       " 'clobbered': 0,\n",
       " 'arthur': 0,\n",
       " 'game': 242,\n",
       " 'labor-management': 0,\n",
       " 'models': 0,\n",
       " 'barrels': 0,\n",
       " 'bonds': 243,\n",
       " 'financially': 244,\n",
       " 'havoc': 0,\n",
       " 'favor': 0,\n",
       " 'debt': 245,\n",
       " 'movements': 0,\n",
       " 'n.y.': 0,\n",
       " 'draw': 751,\n",
       " 'liberal': 0,\n",
       " 'rising': 246,\n",
       " 'fuel': 0,\n",
       " 'reconsider': 0,\n",
       " 'climb': 0,\n",
       " 'rationale': 0,\n",
       " 'far': 247,\n",
       " 'south': 248,\n",
       " 'limbo': 0,\n",
       " 'quote': 0,\n",
       " 'contrasts': 0,\n",
       " 'demanded': 0,\n",
       " 'terminal': 0,\n",
       " 'course': 249,\n",
       " 'advised': 0,\n",
       " 'stake': 250,\n",
       " 'fall': 251,\n",
       " 'dearborn': 0,\n",
       " 'michigan': 0,\n",
       " 'purchases': 0,\n",
       " 'bailout': 0,\n",
       " 'attracting': 0,\n",
       " 'pse': 0,\n",
       " 'occasionally': 0,\n",
       " 'satisfy': 0,\n",
       " 'feeling': 0,\n",
       " 'transportation': 0,\n",
       " 'aim': 252,\n",
       " 'nor': 253,\n",
       " 'robust': 254,\n",
       " 'technologies': 0,\n",
       " 'region': 0,\n",
       " 'cans': 0,\n",
       " 'volatile': 0,\n",
       " 'with': 255,\n",
       " 'difficulty': 0,\n",
       " 'eye': 0,\n",
       " 'victories': 0,\n",
       " 'spielvogel': 256,\n",
       " 'stabilized': 0,\n",
       " 'agreeing': 0,\n",
       " 'wash': 0,\n",
       " 'therefore': 0,\n",
       " 'derivative': 0,\n",
       " 'federal': 257,\n",
       " 'meredith': 0,\n",
       " 'otherwise': 0,\n",
       " 'bargaining': 0,\n",
       " 'grant': 0,\n",
       " 'breaking': 0,\n",
       " 'giving': 258,\n",
       " 'lacks': 0,\n",
       " 'buses': 0,\n",
       " 'affiliate': 0,\n",
       " 'commonly': 0,\n",
       " 'lane': 0,\n",
       " 'production': 259,\n",
       " 'african': 0,\n",
       " 'voters': 0,\n",
       " 'agency': 260,\n",
       " 'nielsen': 0,\n",
       " 'sometimes': 0,\n",
       " 'leadership': 0,\n",
       " 'specifically': 0,\n",
       " 'depositary': 0,\n",
       " 'founded': 0,\n",
       " 'estimated': 261,\n",
       " 'manufacturers': 0,\n",
       " 'court-appointed': 0,\n",
       " 'lenders': 0,\n",
       " 'sent': 262,\n",
       " 'intent': 0,\n",
       " 'deliveries': 0,\n",
       " 'fairly': 0,\n",
       " 'beat': 0,\n",
       " 'spend': 263,\n",
       " 'aside': 0,\n",
       " 'performing': 0,\n",
       " 'scary': 0,\n",
       " 'magnified': 0,\n",
       " 'western': 264,\n",
       " 'winners': 0,\n",
       " 'heritage': 0,\n",
       " 'projects': 265,\n",
       " 'fought': 0,\n",
       " 'gather': 0,\n",
       " 'wave': 0,\n",
       " 'inspector': 0,\n",
       " 'what': 266,\n",
       " 'contributed': 267,\n",
       " 'schools': 0,\n",
       " 'tremendous': 0,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find words that appear in the training set so we can deal with new words separately\n",
    "count_train = np.zeros((nwords,))\n",
    "for snt in corpus_train:\n",
    "    for w in snt:\n",
    "        count_train[w2index[w]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6427.,    17.,    11., ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Dev LL = -4.992084628169756\n"
     ]
    }
   ],
   "source": [
    "# Bigram model as a baseline\n",
    "alpha = 0.1 # add-alpha smoothing\n",
    "probB           = lm.bigramLM(corpus_train, w2index, nwords,alpha)\n",
    "LLB, N          = 0.0, 0\n",
    "bi              = lm.ngramGen(corpus_dev, w2index, 2)\n",
    "\n",
    "for w in bi:\n",
    "    if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "        LLB += np.log(probB[w[0], w[1]])\n",
    "        N += 1\n",
    "        \n",
    "print(\"Bi-gram Dev LL = {0}\".format(LLB / N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network model training:\n"
     ]
    }
   ],
   "source": [
    "# Network model\n",
    "print(\"\\nNetwork model training:\")\n",
    "n        = 3    # Length of n-gram \n",
    "dim      = 10   # Word vector dimension\n",
    "hdim     = 30  # Hidden units\n",
    "neurallm = lm.neuralLM(dim, n, hdim, nwords)  # The network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "\n",
    "lrate = 0.5  # Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6ab275c2e29c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# Average log-likelihood, number of ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mng\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurallm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mng\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mLL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mN\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fqian/mit6.806/hw1/code/languagemodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, ngram, lrate)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Update word vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mgrad\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxgram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "for it in range(10): # passes through the training data\n",
    "    LL, N  = 0.0, 0 # Average log-likelihood, number of ngrams    \n",
    "    for ng in ngrams:\n",
    "        pr = neurallm.update(ng,lrate)\n",
    "        LL += np.log(pr)\n",
    "        N  += 1\n",
    "    print('Train:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n",
    "\n",
    "    #Dev set\n",
    "    LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "    for ng in ngrams2:\n",
    "        if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "            pr = neurallm.prob(ng)\n",
    "            LL += np.log(pr)\n",
    "            N  += 1\n",
    "    print('Dev:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import languagemodel as lm\n",
    "\n",
    "np.random.seed(1)  # for reproducibility\n",
    "\n",
    "corpus_train = lm.readCorpus(\"data/train.txt\")\n",
    "corpus_dev   = lm.readCorpus(\"data/dev.txt\")\n",
    "corpus_test  = lm.readCorpus(\"data/test.txt\")\n",
    "\n",
    "# build a common index (words to integers), mapping rare words (less than 5 occurences) to index 0\n",
    "# nwords = vocabulary size for the models that only see the indexes\n",
    "\n",
    "w2index,nwords = lm.buildIndex(corpus_train+corpus_dev+corpus_test)\n",
    "\n",
    "# find words that appear in the training set so we can deal with new words separately\n",
    "count_train = np.zeros((nwords,))\n",
    "for snt in corpus_train:\n",
    "    for w in snt:\n",
    "        count_train[w2index[w]] += 1\n",
    "\n",
    "# Bigram model as a baseline\n",
    "alpha = 0.1 # add-alpha smoothing\n",
    "probB           = lm.bigramLM(corpus_train, w2index, nwords,alpha)\n",
    "LLB, N          = 0.0, 0\n",
    "bi              = lm.ngramGen(corpus_dev, w2index, 2)\n",
    "for w in bi:\n",
    "    if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "        LLB += np.log(probB[w[0], w[1]])\n",
    "        N += 1\n",
    "print(\"Bi-gram Dev LL = {0}\".format(LLB / N))\n",
    "\n",
    "# Network model\n",
    "print(\"\\nNetwork model training:\")\n",
    "n        = 3    # Length of n-gram \n",
    "dim      = 10   # Word vector dimension\n",
    "hdim     = 30  # Hidden units\n",
    "neurallm = lm.neuralLM(dim, n, hdim, nwords)  # The network model\n",
    "\n",
    "ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "\n",
    "lrate = 0.5  # Learning rate\n",
    "for it in xrange(10): # passes through the training data\n",
    "    LL, N  = 0.0, 0 # Average log-likelihood, number of ngrams    \n",
    "    for ng in ngrams:\n",
    "        pr = neurallm.update(ng,lrate)\n",
    "        LL += np.log(pr)\n",
    "        N  += 1\n",
    "    print('Train:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n",
    "\n",
    "    #Dev set\n",
    "    LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "    for ng in ngrams2:\n",
    "        if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "            pr = neurallm.prob(ng)\n",
    "            LL += np.log(pr)\n",
    "            N  += 1\n",
    "    print('Dev:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ----------------------------------\n",
    "def readCorpus(filename):\n",
    "    fp = open(filename, 'r')\n",
    "    corpus = []  # list of sentences. A sentence is a lists of words.\n",
    "    for line in fp:\n",
    "        line = line.strip()\n",
    "        # replace obvious numbers with <NUM>\n",
    "        line = re.sub(r'\\b\\d+\\b', r'<NUM>', line)\n",
    "        line = re.sub(r'\\b\\d+.\\d+\\b', r'<NUM>', line)\n",
    "        corpus.append(line.split(' '))\n",
    "    return corpus\n",
    "\n",
    "# ----------------------------------\n",
    "def buildIndex(corpus, lowthreshold=5):\n",
    "\n",
    "    # initial index, to be modified later\n",
    "    tmpindex, indx = {}, 0\n",
    "    for snt in corpus:\n",
    "        for w in snt:\n",
    "            if (not tmpindex.has_key(w)):\n",
    "                tmpindex[w] = indx\n",
    "                indx += 1\n",
    "\n",
    "    # eval word counts \n",
    "    counts = np.zeros((indx,))\n",
    "    for snt in corpus:\n",
    "        for w in snt:\n",
    "            counts[tmpindex[w]] += 1\n",
    "\n",
    "    # map all the words with counts leq lowthreshold to index 0\n",
    "    newindex = {}\n",
    "    indx = 1  # 0 reserved for low occurence words\n",
    "    for w in tmpindex.keys():\n",
    "        if (counts[tmpindex[w]] <= lowthreshold):\n",
    "            newindex[w] = 0\n",
    "        else:\n",
    "            newindex[w] = indx\n",
    "            indx += 1\n",
    "            \n",
    "    # add start symbols ... <START-2> <START-1> to the index for use with up to 5-grams\n",
    "    for j in range(1, 5):\n",
    "        newindex[\"<START-\" + str(j) + \">\"] = indx\n",
    "        indx += 1\n",
    "\n",
    "    return newindex, indx\n",
    "\n",
    "# ----------------------------------\n",
    "def ngramGen(corpus, w2index, n):\n",
    "    \"\"\"ngram generator. n is the length of the ngram.\"\"\"\n",
    "    assert(n <= 5)\n",
    "    ngrams = []\n",
    "    start_snt = [\"<START-\" + str(j) + \">\" for j in range(4, 0, -1)]\n",
    "    for snt in corpus:  # sentences\n",
    "        s = start_snt[-n + 1:] + snt\n",
    "        for i in xrange(n - 1, len(s)):\n",
    "            ngrams.append([w2index[w] for w in s[i - n + 1:i + 1]])\n",
    "    return ngrams\n",
    "\n",
    "# -----------------------------------\n",
    "def unigramLM(corpus, w2index, nwords):\n",
    "    uni  = ngramGen(corpus, w2index, 1)\n",
    "    prob = np.zeros((nwords,))\n",
    "    for w in uni:\n",
    "        prob[w[0]] += 1\n",
    "    return prob / float(np.sum(prob))\n",
    "\n",
    "# -----------------------------------\n",
    "def bigramLM(corpus, w2index, nwords, alpha=0.0):\n",
    "    bi   = ngramGen(corpus, w2index, 2)\n",
    "    prob = np.zeros((nwords,nwords))+alpha\n",
    "    for w in bi:\n",
    "        prob[w[0], w[1]] += 1.0\n",
    "    for i in xrange(nwords):\n",
    "        prob[i, :] /= np.sum(prob[i, :])\n",
    "    return prob\n",
    "\n",
    "# =====================================\n",
    "class softmax(object):\n",
    "    def __init__(self, dim, nwords):\n",
    "        self.nwords = nwords    # output dim\n",
    "        self.dim    = dim       # input dim       \n",
    "        self.Wo     = np.zeros((self.nwords,))\n",
    "        self.W      = np.random.randn(self.dim, self.nwords) / np.sqrt(self.dim)\n",
    "        self.prob   = np.ones((self.nwords,)) / float(self.nwords)\n",
    "        self.G2o    = 1e-12 * np.ones((self.nwords,)) # adagrad sum squared gradients for Wo\n",
    "        self.G2     = 1e-12 * np.ones((self.nwords,)) # adagrad sum squared gradients for W\n",
    "        \n",
    "    def apply(self, x):\n",
    "        z           = self.Wo + np.dot(x, self.W)\n",
    "        self.prob   = np.exp(z - np.max(z))\n",
    "        self.prob  /= np.sum(self.prob)\n",
    "        return self.prob\n",
    "\n",
    "    # update bias, accum wordvec gradient, return dlogP[y]/dx\n",
    "    def backprop(self, x, lrate, y):\n",
    "        grad       = -self.prob\n",
    "        grad[y]   += 1.0  # dlogP[y]/dz\n",
    "        xdelta     = np.dot(self.W, grad)  # dlogP[y]/dx\n",
    "        xnorm2     = np.sum(x ** 2)\n",
    "        self.G2o  += grad ** 2\n",
    "        self.G2   += xnorm2 * grad ** 2\n",
    "        self.Wo   += lrate * grad / np.sqrt(self.G2o)\n",
    "        self.W    += lrate * np.outer(x, grad / np.sqrt(self.G2))\n",
    "        return xdelta\n",
    "\n",
    "# =====================================\n",
    "class NNlayer(object):\n",
    "    def __init__(self, idim, odim):\n",
    "        self.idim = idim\n",
    "        self.odim = odim\n",
    "        self.W    = np.random.randn(self.idim, self.odim) / np.sqrt(self.idim)\n",
    "        self.Wo   = np.zeros(self.odim,)\n",
    "        # adaGrad sum squared gradients\n",
    "        self.G2o  = 1e-12 * np.ones((self.odim,))\n",
    "        self.G2   = 1e-12 * np.ones((self.odim,))\n",
    "        self.f    = np.zeros((self.odim,))  # activation of output units\n",
    "\n",
    "    def apply(self, x):\n",
    "        self.f = np.tanh(self.Wo + np.dot(x, self.W))\n",
    "        return self.f \n",
    "\n",
    "    def backprop(self, x, lrate, delta):\n",
    "        grad       = (1.0 - self.f ** 2) * delta  # dJ/dz = df/dz * delta.  (dtanh/dx = 1 - tanh^2) \n",
    "        xdelta     = np.dot(self.W, grad)         # dJ/dx to be returned\n",
    "        xnorm2     = np.sum(x ** 2)\n",
    "        self.G2o  += grad ** 2\n",
    "        self.G2   += xnorm2 * grad ** 2\n",
    "        self.Wo   += lrate * grad / np.sqrt(self.G2o)\n",
    "        self.W    += lrate * np.outer(x, grad / np.sqrt(self.G2))\n",
    "        return xdelta\n",
    "\n",
    "# =====================================\n",
    "class neuralLM(object):\n",
    "    def __init__(self, dim, ngram, hdim, nwords):\n",
    "        self.dim    = dim       # word vector dimension\n",
    "        self.ncond  = ngram - 1 # number of conditioning words\n",
    "        self.hdim   = hdim      # number of hidden layer units\n",
    "        self.nwords = nwords    # vocab size\n",
    "\n",
    "        self.wvec    = np.random.randn(self.nwords, self.dim)  # word vectors\n",
    "        self.G2      = 1e-12 * np.ones((self.nwords,))         # adaGrad sum of squares for word vectors\n",
    "        self.hiddenL = NNlayer(self.ncond * self.dim, self.hdim)\n",
    "        self.outputL = softmax(self.hdim, self.nwords)\n",
    "        \n",
    "    def prob(self, ngram):\n",
    "        xgram, y = ngram[:-1], ngram[-1]\n",
    "        x        = np.concatenate(self.wvec[xgram, :])\n",
    "        fh       = self.hiddenL.apply(x)\n",
    "        proba    = self.outputL.apply(fh)\n",
    "        return proba[y]\n",
    "\n",
    "    def update(self, ngram, lrate):\n",
    "        # Propagate (i.e. feed-forward pass)\n",
    "        xgram, y = ngram[:-1], ngram[-1]\n",
    "        x        = np.concatenate(self.wvec[xgram, :])\n",
    "        fh       = self.hiddenL.apply(x)\n",
    "        pr       = self.outputL.apply(fh)\n",
    "        # Backpropagate (and update layers)\n",
    "        dh       = self.outputL.backprop(fh, lrate, y)\n",
    "        dx       = self.hiddenL.backprop(x, lrate, dh)\n",
    "        # Update word vectors\n",
    "        grad     = np.reshape(dx, (self.ncond, self.dim))\n",
    "        for i in xrange(self.ncond):\n",
    "            self.G2[xgram[i]]      += np.sum(grad[i, :] ** 2)\n",
    "            self.wvec[xgram[i], :] += lrate * grad[i, :] / np.sqrt(self.G2[xgram[i]])\n",
    "\n",
    "        return pr[y]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
