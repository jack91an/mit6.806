{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import languagemodel as lm\n",
    "\n",
    "np.random.seed(1)  # for reproducibility\n",
    "\n",
    "corpus_train = lm.readCorpus(\"data/train.txt\")\n",
    "corpus_dev   = lm.readCorpus(\"data/dev.txt\")\n",
    "corpus_test  = lm.readCorpus(\"data/test.txt\")\n",
    "\n",
    "# build a common index (words to integers), mapping rare words (less than 5 occurences) to index 0\n",
    "# nwords = vocabulary size for the models that only see the indexes\n",
    "\n",
    "w2index,nwords = lm.buildIndex(corpus_train+corpus_dev+corpus_test)\n",
    "\n",
    "# find words that appear in the training set so we can deal with new words separately\n",
    "count_train = np.zeros((nwords,))\n",
    "for snt in corpus_train:\n",
    "    for w in snt:\n",
    "        count_train[w2index[w]] += 1\n",
    "\n",
    "# Bigram model as a baseline\n",
    "alpha = 0.1 # add-alpha smoothing\n",
    "probB           = lm.bigramLM(corpus_train, w2index, nwords,alpha)\n",
    "LLB, N          = 0.0, 0\n",
    "bi              = lm.ngramGen(corpus_dev, w2index, 2)\n",
    "for w in bi:\n",
    "    if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "        LLB += np.log(probB[w[0], w[1]])\n",
    "        N += 1\n",
    "print(\"Bi-gram Dev LL = {0}\".format(LLB / N))\n",
    "\n",
    "# Network model\n",
    "print(\"\\nNetwork model training:\")\n",
    "n        = 3    # Length of n-gram \n",
    "dim      = 10   # Word vector dimension\n",
    "hdim     = 30  # Hidden units\n",
    "neurallm = lm.neuralLM(dim, n, hdim, nwords)  # The network model\n",
    "\n",
    "ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "\n",
    "lrate = 0.5  # Learning rate\n",
    "for it in xrange(10): # passes through the training data\n",
    "    LL, N  = 0.0, 0 # Average log-likelihood, number of ngrams    \n",
    "    for ng in ngrams:\n",
    "        pr = neurallm.update(ng,lrate)\n",
    "        LL += np.log(pr)\n",
    "        N  += 1\n",
    "    print('Train:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n",
    "\n",
    "    #Dev set\n",
    "    LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "    for ng in ngrams2:\n",
    "        if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "            pr = neurallm.prob(ng)\n",
    "            LL += np.log(pr)\n",
    "            N  += 1\n",
    "    print('Dev:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Dev LL = -4.992084628169756\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import languagemodel as lm\n",
    "\n",
    "np.random.seed(1)  # for reproducibility\n",
    "\n",
    "corpus_train = lm.readCorpus(\"data/train.txt\")\n",
    "corpus_dev   = lm.readCorpus(\"data/dev.txt\")\n",
    "corpus_test  = lm.readCorpus(\"data/test.txt\")\n",
    "\n",
    "# build a common index (words to integers), mapping rare words (less than 5 occurences) to index 0\n",
    "# nwords = vocabulary size for the models that only see the indexes\n",
    "\n",
    "w2index,nwords = lm.buildIndex(corpus_train+corpus_dev+corpus_test)\n",
    "\n",
    "# find words that appear in the training set so we can deal with new words separately\n",
    "count_train = np.zeros((nwords,))\n",
    "for snt in corpus_train:\n",
    "    for w in snt:\n",
    "        count_train[w2index[w]] += 1\n",
    "\n",
    "# Bigram model as a baseline\n",
    "alpha = 0.1 # add-alpha smoothing\n",
    "probB           = lm.bigramLM(corpus_train, w2index, nwords,alpha)\n",
    "LLB, N          = 0.0, 0\n",
    "bi              = lm.ngramGen(corpus_dev, w2index, 2)\n",
    "for w in bi:\n",
    "    if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "        LLB += np.log(probB[w[0], w[1]])\n",
    "        N += 1\n",
    "print(\"Bi-gram Dev LL = {0}\".format(LLB / N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure baseline bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Dev LL = -4.948425066555479 with alpha 0.005\n",
      "Bi-gram Dev LL = -4.883153686434726 with alpha 0.01\n",
      "Bi-gram Dev LL = -4.864619740209547 with alpha 0.015\n",
      "Bi-gram Dev LL = -4.860978607317725 with alpha 0.02\n",
      "Bi-gram Dev LL = -4.863757939080634 with alpha 0.025\n",
      "Bi-gram Dev LL = -4.869712234971148 with alpha 0.030000000000000002\n",
      "Bi-gram Dev LL = -4.877345106194942 with alpha 0.034999999999999996\n",
      "Bi-gram Dev LL = -4.885883828299522 with alpha 0.04\n",
      "Bi-gram Dev LL = -4.89489816262743 with alpha 0.045\n",
      "Bi-gram Dev LL = -4.904135817380125 with alpha 0.049999999999999996\n",
      "Bi-gram Dev LL = -4.913443507489412 with alpha 0.055\n",
      "Bi-gram Dev LL = -4.922725970490986 with alpha 0.06\n",
      "Bi-gram Dev LL = -4.931923344358705 with alpha 0.065\n",
      "Bi-gram Dev LL = -4.940998056193698 with alpha 0.07\n",
      "Bi-gram Dev LL = -4.949926915954853 with alpha 0.07500000000000001\n",
      "Bi-gram Dev LL = -4.958696190725572 with alpha 0.08\n",
      "Bi-gram Dev LL = -4.96729845155322 with alpha 0.085\n",
      "Bi-gram Dev LL = -4.975730508786532 with alpha 0.09000000000000001\n",
      "Bi-gram Dev LL = -4.983992034390634 with alpha 0.095\n",
      "Bi-gram Dev LL = -4.992084628169756 with alpha 0.1\n"
     ]
    }
   ],
   "source": [
    "llh_bi_list = []\n",
    "for alphax in np.linspace(0.005, 0.1, 20):\n",
    "    probB           = lm.bigramLM(corpus_train, w2index, nwords,alphax)\n",
    "    LLB, N          = 0.0, 0\n",
    "    bi              = lm.ngramGen(corpus_dev, w2index, 2)\n",
    "    for w in bi:\n",
    "        if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "            LLB += np.log(probB[w[0], w[1]])\n",
    "            N += 1\n",
    "    print(\"Bi-gram Dev LL = {0} with alpha {1}\".format(LLB / N, alphax))\n",
    "    llh_bi_list.append(LLB / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10a0e4390>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEZCAYAAABmTgnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWf8P0M0OV4udwiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a6266d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.linspace(0.005, 0.1, 20), llh_bi_list)\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.title(\"average log likelihood of development corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram Test LL = -4.8457415193597155 with alpha 0.02\n"
     ]
    }
   ],
   "source": [
    "bi_test = lm.ngramGen(corpus_test, w2index, 2)\n",
    "alpha = 0.02\n",
    "probB           = lm.bigramLM(corpus_train, w2index, nwords,alpha)\n",
    "LLB, N          = 0.0, 0\n",
    "\n",
    "for w in bi_test:\n",
    "    if (count_train[w[1]]>0): # for now, skip target words not seen in training\n",
    "        LLB += np.log(probB[w[0], w[1]])\n",
    "        N += 1\n",
    "print(\"Bi-gram Test LL = {0} with alpha {1}\".format(LLB / N, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2, dim=5, hdim=10, dev llh=-4.904785539558707\n",
      "n=2, dim=5, hdim=30, dev llh=-4.843481341786308\n",
      "n=2, dim=5, hdim=50, dev llh=-4.852710258312751\n",
      "n=2, dim=10, hdim=10, dev llh=-4.890904005127846\n",
      "n=2, dim=10, hdim=30, dev llh=-4.794984424580786\n",
      "n=2, dim=10, hdim=50, dev llh=-4.791471388025544\n",
      "n=2, dim=20, hdim=10, dev llh=-4.89460135846894\n",
      "n=2, dim=20, hdim=30, dev llh=-4.78056648744739\n",
      "n=2, dim=20, hdim=50, dev llh=-4.748481825794477\n",
      "n=3, dim=5, hdim=10, dev llh=-4.928681366597829\n",
      "n=3, dim=5, hdim=30, dev llh=-4.7964473688033475\n",
      "n=3, dim=5, hdim=50, dev llh=-4.801392721426568\n",
      "n=3, dim=10, hdim=10, dev llh=-4.856130935224388\n",
      "n=3, dim=10, hdim=30, dev llh=-4.7607189154156435\n",
      "n=3, dim=10, hdim=50, dev llh=-4.7761424349909625\n",
      "n=3, dim=20, hdim=10, dev llh=-4.861990937226091\n",
      "n=3, dim=20, hdim=30, dev llh=-4.755165327400062\n",
      "n=3, dim=20, hdim=50, dev llh=-4.735656115163282\n",
      "n=4, dim=5, hdim=10, dev llh=-4.90576103197\n",
      "n=4, dim=5, hdim=30, dev llh=-4.84448892606861\n",
      "n=4, dim=5, hdim=50, dev llh=-4.817928180287612\n",
      "n=4, dim=10, hdim=10, dev llh=-4.922317775332129\n",
      "n=4, dim=10, hdim=30, dev llh=-4.791019341413742\n",
      "n=4, dim=10, hdim=50, dev llh=-4.781944539915543\n",
      "n=4, dim=20, hdim=10, dev llh=-4.8960483944329445\n",
      "n=4, dim=20, hdim=30, dev llh=-4.798330170885385\n",
      "n=4, dim=20, hdim=50, dev llh=-4.7634669169472215\n",
      "n=5, dim=5, hdim=10, dev llh=-4.991303710743656\n",
      "n=5, dim=5, hdim=30, dev llh=-4.858464873102248\n",
      "n=5, dim=5, hdim=50, dev llh=-4.805399297770563\n",
      "n=5, dim=10, hdim=10, dev llh=-4.8981129917620745\n",
      "n=5, dim=10, hdim=30, dev llh=-4.821929047244881\n",
      "n=5, dim=10, hdim=50, dev llh=-4.77881321472532\n",
      "n=5, dim=20, hdim=10, dev llh=-4.916921096021701\n",
      "n=5, dim=20, hdim=30, dev llh=-4.814204064169429\n",
      "n=5, dim=20, hdim=50, dev llh=-4.794959422042593\n"
     ]
    }
   ],
   "source": [
    "neural_result1 = []\n",
    "\n",
    "iter_num = 2\n",
    "lrate = 0.5  # Learning rate\n",
    "for n in [2,3,4,5]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    for dim in [5, 10, 20]:\n",
    "        for hdim in [10, 30, 50]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams2:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, dev llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result1.append([n, dim, hdim, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, dim=50, hdim=40, dev llh=-4.615536150004457\n",
      "n=3, dim=50, hdim=50, dev llh=-4.6432565387426985\n",
      "n=3, dim=50, hdim=60, dev llh=-4.630532437885575\n",
      "n=3, dim=75, hdim=40, dev llh=-4.6397915786224555\n",
      "n=3, dim=75, hdim=50, dev llh=-4.626198648142621\n",
      "n=3, dim=75, hdim=60, dev llh=-4.607094358766884\n",
      "n=3, dim=100, hdim=40, dev llh=-4.623066747344818\n",
      "n=3, dim=100, hdim=50, dev llh=-4.63456676862269\n",
      "n=3, dim=100, hdim=60, dev llh=-4.626712758690609\n"
     ]
    }
   ],
   "source": [
    "neural_result2 = []\n",
    "\n",
    "iter_num = 10\n",
    "lrate = 0.5  # Learning rate\n",
    "for n in [3]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    for dim in [50, 75, 100]:\n",
    "        for hdim in [40, 50, 60]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams2:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, dev llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result2.append([n, dim, hdim, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, dim=75, hdim=60, dev llh=-4.6397105792343725\n",
      "n=3, dim=75, hdim=70, dev llh=-4.632634290665759\n",
      "n=3, dim=75, hdim=80, dev llh=-4.6349324644524925\n"
     ]
    }
   ],
   "source": [
    "neural_result2 = []\n",
    "\n",
    "iter_num = 5\n",
    "lrate = 0.5  # Learning rate\n",
    "for n in [3]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    for dim in [75]:\n",
    "        for hdim in [60,70,80]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams2:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, dev llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result2.append([n, dim, hdim, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, dim=75, hdim=70, dev llh=-4.587264484668621\n"
     ]
    }
   ],
   "source": [
    "neural_result3 = []\n",
    "\n",
    "iter_num = 10\n",
    "lrate = 0.5  # Learning rate\n",
    "for n in [3]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    ngrams_test = lm.ngramGen(corpus_test,w2index,n)\n",
    "    for dim in [75]:\n",
    "        for hdim in [70]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams_test:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, test llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result3.append([n, dim, hdim, temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, dim=10, hdim=10, dev llh=-4.75421944995654\n",
      "n=3, dim=10, hdim=30, dev llh=-4.668805868425711\n",
      "n=3, dim=10, hdim=50, dev llh=-4.657645435001167\n",
      "n=3, dim=10, hdim=75, dev llh=-4.65722058607932\n",
      "n=3, dim=10, hdim=100, dev llh=-4.658201748436989\n",
      "n=3, dim=10, hdim=200, dev llh=-4.669317512159063\n"
     ]
    }
   ],
   "source": [
    "# neural_result4 = []\n",
    "\n",
    "iter_num = 5\n",
    "lrate = 0.5  # Learning rate\n",
    "for n in [3]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    ngrams_test = lm.ngramGen(corpus_test,w2index,n)\n",
    "    for dim in [10]:\n",
    "        for hdim in [150]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams_test:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, test llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result4.append([n, dim, hdim, np.mean(temp_result), temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3, dim=10, hdim=20, test llh=-4.6895681331534185\n"
     ]
    }
   ],
   "source": [
    "for n in [3]:\n",
    "    ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "    ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "    ngrams_test = lm.ngramGen(corpus_test,w2index,n)\n",
    "    for dim in [10]:\n",
    "        for hdim in [20]:\n",
    "            neurallm = lm.neuralLM(dim, n, hdim, nwords)\n",
    "            temp_result = []\n",
    "\n",
    "            for it in range(iter_num): # passes through the training data\n",
    "                for ng in ngrams:\n",
    "                    pr = neurallm.update(ng,lrate)\n",
    "\n",
    "                #Dev set\n",
    "                LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "                for ng in ngrams_test:\n",
    "                    if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "                        pr = neurallm.prob(ng)\n",
    "                        LL += np.log(pr)\n",
    "                        N  += 1\n",
    "                temp_result.append(LL/N)\n",
    "            print('n={0}, dim={1}, hdim={2}, test llh={3}'.format(n, dim, hdim, np.mean(temp_result)))\n",
    "            neural_result4.append([n, dim, hdim, np.mean(temp_result), temp_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10b7f31d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEZCAYAAACAZ8KHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMzOriQOHmZnV5P8DHEZPjCCfpzQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b826550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_result4_sorted = sorted(neural_result4, key=lambda x: x[2])\n",
    "\n",
    "avg_llh_m = [a[3] for a in neural_result4_sorted]\n",
    "all_m = [a[2] for a in neural_result4_sorted]\n",
    "plt.plot(all_m, avg_llh_m)\n",
    "plt.xlabel(\"m: number of hidden units\")\n",
    "plt.title(\"average log likelihood on testing corpus with n=3 and d=10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_stn_1 = [[\"the\", \"choice\", \"of\", \"their\", \"class\", \"is\", \"good\"]]\n",
    "test_stn_2 = [[\"the\", \"choice\", \"of\", \"there\", \"class\", \"is\", \"good\"]]\n",
    "\n",
    "\n",
    "test_trigram_1 = lm.ngramGen(test_stn_1,w2index,3)\n",
    "test_trigram_2 = lm.ngramGen(test_stn_2,w2index,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1418, 1417, 620],\n",
       " [1417, 620, 1092],\n",
       " [620, 1092, 912],\n",
       " [1092, 912, 1056],\n",
       " [912, 1056, 0],\n",
       " [1056, 0, 230],\n",
       " [0, 230, 598]]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trigram_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.26790220051\n"
     ]
    }
   ],
   "source": [
    "LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "for ng in test_trigram_1:\n",
    "    pr = neurallm.prob(ng)\n",
    "    LL += np.log(pr)\n",
    "    N  += 1\n",
    "print(LL/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.05290330802\n"
     ]
    }
   ],
   "source": [
    "LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "for ng in test_trigram_2:\n",
    "    pr = neurallm.prob(ng)\n",
    "    LL += np.log(pr)\n",
    "    N  += 1\n",
    "print(LL/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network model training:\n",
      "Train:\t0\tLL = -5.183838706612703\n",
      "Dev:\t0\tLL = -4.83666408983967\n",
      "Train:\t1\tLL = -4.630877101085274\n",
      "Dev:\t1\tLL = -4.7168726314392515\n",
      "Train:\t2\tLL = -4.466241028270229\n",
      "Dev:\t2\tLL = -4.668948482547839\n",
      "Train:\t3\tLL = -4.367345741095842\n",
      "Dev:\t3\tLL = -4.644548897022256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-1d06c403e836>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mLL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# Average log-likelihood, number of ngrams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mng\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneurallm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mng\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mLL\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mN\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fqian/mit6.806/hw1/code/languagemodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, ngram, lrate)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mpr\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Backpropagate (and update layers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mdh\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mdx\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddenL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Update word vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/fqian/mit6.806/hw1/code/languagemodel.py\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, x, lrate, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG2\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0mxnorm2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWo\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0mlrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG2o\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m    \u001b[0;34m+=\u001b[0m \u001b[0mlrate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mouter\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Network model\n",
    "print(\"\\nNetwork model training:\")\n",
    "n        = 3    # Length of n-gram \n",
    "dim      = 50   # Word vector dimension\n",
    "hdim     = 100  # Hidden units\n",
    "neurallm = lm.neuralLM(dim, n, hdim, nwords)  # The network model\n",
    "\n",
    "ngrams = lm.ngramGen(corpus_train,w2index,n)\n",
    "ngrams2 = lm.ngramGen(corpus_dev,w2index,n)\n",
    "\n",
    "lrate = 0.5  # Learning rate\n",
    "for it in range(5): # passes through the training data\n",
    "    LL, N  = 0.0, 0 # Average log-likelihood, number of ngrams    \n",
    "    for ng in ngrams:\n",
    "        pr = neurallm.update(ng,lrate)\n",
    "        LL += np.log(pr)\n",
    "        N  += 1\n",
    "    print('Train:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n",
    "\n",
    "    #Dev set\n",
    "    LL, N = 0.0, 0 # Average log-likelihood, number of ngrams\n",
    "    for ng in ngrams2:\n",
    "        if (count_train[ng[-1]]>0): # for now, skip target words not seen in training\n",
    "            pr = neurallm.prob(ng)\n",
    "            LL += np.log(pr)\n",
    "            N  += 1\n",
    "    print('Dev:\\t{0}\\tLL = {1}'.format(it, LL / N)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
